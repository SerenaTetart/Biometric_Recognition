{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport re\nimport os\nimport random\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\ntarget_shape = (96, 96)\nBATCH_SIZE = 512\nimages_path = '/kaggle/input/socofing/socofing/SOCOFing/Real'\nimages_path2 = '/kaggle/input/socofing/socofing/SOCOFing/Altered'","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:41:44.430534Z","iopub.execute_input":"2021-10-05T12:41:44.430822Z","iopub.status.idle":"2021-10-05T12:41:44.436197Z","shell.execute_reply.started":"2021-10-05T12:41:44.430791Z","shell.execute_reply":"2021-10-05T12:41:44.435295Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import cv2\n\ndef preprocess_image(filename):\n    \"\"\"\n    Load the specified file, preprocess it and\n    resize it to the target shape.\n    \"\"\"\n    img = cv2.imread(filename)\n    img = cv2.resize(img, target_shape)\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:41:45.725376Z","iopub.execute_input":"2021-10-05T12:41:45.725668Z","iopub.status.idle":"2021-10-05T12:41:45.732090Z","shell.execute_reply.started":"2021-10-05T12:41:45.725630Z","shell.execute_reply":"2021-10-05T12:41:45.731271Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndicImages = {}\ndataset_x = []; dataset_y = []\nfor f in os.listdir(images_path):\n    fClass = int(re.findall('[0-9]+', f)[0])\n    dataset_x.append(images_path+'/'+f)\n    dataset_y.append(fClass)\nfor dirs in os.listdir(images_path2):\n    for f in os.listdir(images_path2+'/'+dirs):\n        fClass = int(re.findall('[0-9]+', f)[0])\n        dataset_x.append(images_path2+'/'+dirs+'/'+f)\n        dataset_y.append(fClass)\n    \ndataset_x = np.array(dataset_x)\ndataset_y = np.array(dataset_y)\n    \nx_train, x_val, label_train, label_val = train_test_split(dataset_x, dataset_y, test_size=0.1)\n\nprint(dataset_x.shape, dataset_y.shape)\nprint(x_train.shape, label_train.shape)\nprint(x_val.shape, label_val.shape)\n\ndel(dataset_x)\ndel(dataset_y)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:41:47.646050Z","iopub.execute_input":"2021-10-05T12:41:47.646595Z","iopub.status.idle":"2021-10-05T12:41:47.891221Z","shell.execute_reply.started":"2021-10-05T12:41:47.646558Z","shell.execute_reply":"2021-10-05T12:41:47.890452Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.subplot(1,3,1)\nplt.imshow(preprocess_image(random.choice(x_train)))\n\nplt.subplot(1,3,2)\nplt.imshow(preprocess_image(random.choice(x_train)))\n\nplt.subplot(1,3,3)\nplt.imshow(preprocess_image(random.choice(x_train)))","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:41:49.710065Z","iopub.execute_input":"2021-10-05T12:41:49.710606Z","iopub.status.idle":"2021-10-05T12:41:50.097419Z","shell.execute_reply.started":"2021-10-05T12:41:49.710568Z","shell.execute_reply":"2021-10-05T12:41:50.096718Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\nfrom imgaug import augmenters as iaa\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, x, label, batch_size=32, shuffle=True):\n        'Initialization'\n        self.x = x\n        self.label = label\n        \n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return len(self.x) // self.batch_size\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        x1_batch_tmp = self.x[index*self.batch_size:(index+1)*self.batch_size]\n        x1_batch = []\n        for f in x1_batch_tmp: x1_batch.append(preprocess_image(f))\n        x1_batch = np.array(x1_batch)\n        label_batch = self.label[index*self.batch_size:(index+1)*self.batch_size]\n        x1_batch = tf.keras.applications.vgg19.preprocess_input(x1_batch)\n                \n        return x1_batch, label_batch\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            self.x, self.label = shuffle(self.x, self.label)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:41:52.178113Z","iopub.execute_input":"2021-10-05T12:41:52.178365Z","iopub.status.idle":"2021-10-05T12:41:52.188293Z","shell.execute_reply.started":"2021-10-05T12:41:52.178338Z","shell.execute_reply":"2021-10-05T12:41:52.187423Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_gen = DataGenerator(x_train, label_train, batch_size=BATCH_SIZE, shuffle=True)\nval_gen = DataGenerator(x_val, label_val, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:41:54.308255Z","iopub.execute_input":"2021-10-05T12:41:54.308506Z","iopub.status.idle":"2021-10-05T12:41:54.324242Z","shell.execute_reply.started":"2021-10-05T12:41:54.308478Z","shell.execute_reply":"2021-10-05T12:41:54.323509Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import Model\n\ndef Get_Model():\n    vgg = tf.keras.applications.vgg19.VGG19(input_shape=target_shape+(3,), include_top=False, weights='imagenet')\n    vgg.trainable = False\n\n    flatten = layers.Flatten()(vgg.output)\n    dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n    dense1 = layers.Dropout(0.2)(dense1)\n    #dense1 = layers.BatchNormalization()(dense1)\n    dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n    dense2 = layers.Dropout(0.2)(dense2)\n    #dense2 = layers.BatchNormalization()(dense2)\n    output = layers.Dense(256)(dense2)\n    output = layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(output)\n\n    return Model(vgg.input, output, name=\"Embedding\")\n    \nmodel = Get_Model()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:41:57.196335Z","iopub.execute_input":"2021-10-05T12:41:57.196597Z","iopub.status.idle":"2021-10-05T12:41:57.578527Z","shell.execute_reply.started":"2021-10-05T12:41:57.196569Z","shell.execute_reply":"2021-10-05T12:41:57.577812Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss=tfa.losses.TripletSemiHardLoss())\n\nhistory = model.fit(\n    x=train_gen,\n    validation_data=val_gen,\n    epochs=100)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T13:03:29.968216Z","iopub.execute_input":"2021-10-05T13:03:29.968508Z","iopub.status.idle":"2021-10-05T14:34:54.436334Z","shell.execute_reply.started":"2021-10-05T13:03:29.968478Z","shell.execute_reply":"2021-10-05T14:34:54.435583Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"model.save_weights('tripletLoss_weight.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:39:11.868212Z","iopub.execute_input":"2021-10-05T14:39:11.868487Z","iopub.status.idle":"2021-10-05T14:39:12.066667Z","shell.execute_reply.started":"2021-10-05T14:39:11.868458Z","shell.execute_reply":"2021-10-05T14:39:12.065760Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model.load_weights('tripletLoss_weight.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-05T12:42:10.144999Z","iopub.execute_input":"2021-10-05T12:42:10.145297Z","iopub.status.idle":"2021-10-05T12:42:10.250894Z","shell.execute_reply.started":"2021-10-05T12:42:10.145262Z","shell.execute_reply":"2021-10-05T12:42:10.250015Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def Test_Image(Anchor_img, Test_img):\n\n    anchor = preprocess_image(Anchor_img)\n    test = preprocess_image(Test_img)\n\n    anchor = tf.expand_dims(anchor, 0)\n    test = tf.expand_dims(test, 0)\n\n    anchor_embedding, test_embedding = (\n        model(anchor),\n        model(test),\n    ) # Return (1, 256) Vector = last logits from model\n    \n    ap_distance = tf.reduce_sum(tf.square(anchor_embedding - test_embedding), 1)\n    \n    return ap_distance.numpy()\n    \ntab1 = []; tab2 = []; tab3 = []\nfor f in os.listdir(images_path):\n    fClass = int(re.findall('[0-9]+', f)[0])\n    if(fClass == 1 and str(f) != '1__M_Left_index_finger.BMP'):\n        res = Test_Image(images_path+'/1__M_Left_index_finger.BMP', images_path+'/'+str(f))\n        tab1.append(res)\n    elif(fClass == 2):\n        res = Test_Image(images_path+'/1__M_Left_index_finger.BMP', images_path+'/'+str(f))\n        tab2.append(res)\n    elif(fClass == 3):\n        res = Test_Image(images_path+'/1__M_Left_index_finger.BMP', images_path+'/'+str(f))\n        tab3.append(res)\nval1 = 0; val2 = 0; val3 = 0\nfor emb in tab1:\n    val1 += emb\nval1 = val1/len(tab1)\nfor emb in tab2:\n    val2 += emb\nval2 = val2/len(tab2)\nfor emb in tab3:\n    val3 += emb\nval3 = val3/len(tab3)\n\nprint('\\nmoy1:', val1)\nprint('moy2:', val2)\nprint('moy3:', val3)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T14:39:19.081803Z","iopub.execute_input":"2021-10-05T14:39:19.082327Z","iopub.status.idle":"2021-10-05T14:39:19.700531Z","shell.execute_reply.started":"2021-10-05T14:39:19.082288Z","shell.execute_reply":"2021-10-05T14:39:19.699167Z"},"trusted":true},"execution_count":41,"outputs":[]}]}
